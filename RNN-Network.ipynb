{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "performance =  0.9618\n"
     ]
    }
   ],
   "source": [
    "## 3계층의 신경망으로 MNIST 데이터를 학습하는 코드\n",
    "\n",
    "# numpy : 행렬이나 일반적으로 대규모 다차원 배열을 쉽게 처리 할 수 있게 해주는 파이썬 라이브러리\n",
    "import numpy\n",
    "# 시그모이드 함수 사용을 위해 scipy.special 라이브러리 불러와서 expit() 함수 씀  \n",
    "import scipy.special\n",
    "# 행렬 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot\n",
    "# 시각화가 외부 윈도우가 아닌 현재 노트북에서 보이도록 설정\n",
    "%matplotlib inline\n",
    "\n",
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    # 신경망 초기화\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # 입력, 은닉, 출력 계층의 노드 개수 설정\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # 가중치 행렬 wih & who\n",
    "        # wih = (은닉 노드 * 입력 노드) 의 크기를 가지는 입력 -> 은닉 가중치 행렬 WI\n",
    "        # who = (출력 노드 * 은닉 노드) 의 크기를 가지는 은닉 -> 입력 가중치 행렬 WH\n",
    "        # numpy.random.rand(행, 열) : 0 ~ 1 사이의 값\n",
    "        # self.wih = numpy.random.rand(self.hnodes, self,inodes) - 0.5\n",
    "        # self.who = numpy.random.rand(self.onodes, self,hnodes) - 0.5\n",
    "        \n",
    "        # 더 정교하게 가중치 초기화\n",
    "        # 1/ 루트(들어오는 연결 노드의 개수) 의 표준편차를 가지는 정규분포\n",
    "        # pow 함수로 제곱\n",
    "        # numpy.random.normal(정규 분포의 중심, 표준편차, (행, 열))\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # 학습률\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # 활성화 함수로 시그모이드 함수 이용\n",
    "        # 람다 익명 함수 : 매개변수를 x로해서 시그모이드 함수를 activation_function()에 할당 \n",
    "        # expit : 시그모이드 함수\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # 신경망 학습\n",
    "    def train(self, inputs_list, targets_list):        \n",
    "        # 입력 리스트를 2차원 행렬로 변환\n",
    "        # numpy.transpose() == .T\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # 은닉 계층으로 들어오는 신호 계산\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # 은닉 계층에서 나가는 신호 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # 최종 계층으로 들어오는 신호 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # 최종 계층에서 나가는 신호 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        # 출력 계층 오차는 (실제값 - 계산 값)\n",
    "        output_errors = targets - final_outputs\n",
    "        # 은닉 계층의 오차는 가중치에 의해 나누니 출력 계층의 오차들을 재조합해 계산\n",
    "        # hidden_errors = W tras * errors \n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # Wjk = 학습률 * 에러k * sigmoid(Ok) * (1- sigmoid(Ok)) * OjT\n",
    "        # 시그모이드 : 활성화 함수\n",
    "        \n",
    "        # numpy.dot() : 매트릭스의 곱 계산\n",
    "        # numpy.transpose() 행과 열을 바꿈 \n",
    "        # 은닉 계층과 출력 계층 간의 가중치 업데이트\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # 입력 계층과 은닉 계층 간의 가중치 업데이트\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # 신경망 질의\n",
    "    def query(self, inputs_list):\n",
    "        # 입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # 은닉 계층으로 들어오는 신호 계산\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # 은닉 계층에서 나가는 신호 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # 최종 계층으로 들어오는 신호 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # 최종 계층에서 나가는 신호 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "\n",
    "input_nodes = 784\n",
    "# 임시 : 신경망은 입력 값에서 어떤 특징 또는 패턴을 찾아냄 -> 이러한 특징 또는 패턴은 입력 값의 수보다는 작은 형태로 표현 -> 주요 특징 찾아냄\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.3\n",
    "\n",
    "# 신경망 인스턴스 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "# mnist 학습데이터\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "# readlines() 는 쉽지만 불러오는 데이터 너무 클떄는 전체파일을 메모리에 올리기 떄문에 비효율\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# epoch(주기) : 학습 데이터가 학습을 위해 사용되는 횟수를 의미\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(e)\n",
    "    # 학습 데이터 모음 내의 모든 레코드 탐색\n",
    "    for record in training_data_list:\n",
    "        # 레코드를 쉼표에 의해 분리\n",
    "        all_values = record.split(',')\n",
    "        \n",
    "        # asfarray() 문자열을 실수로 변환 한 다음에 그 숫자로 구성된 배열을 생성\n",
    "        # reshape((28,28)) 는 28*28의 정방행렬로 만들어줌\n",
    "        # image_array = numpy.asfarray(all_values[1:]).reshape((28, 28))\n",
    "        # cmap = 'Greys' 를 지정해 회색톤의 색상 팔레트를 사용\n",
    "        # matplotlib.pyplot.imshow(image_array, cmap ='Greys', interpolation='None')\n",
    "\n",
    "        # 입력 값의 범위와 값 조정\n",
    "        inputs = (numpy.asfarray(all_values[1:])/255.0 * 0.99) + 0.01\n",
    "        \n",
    "        # 결과 값 생성 (실제 값 외에는 모두 0.01)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        \n",
    "        # all_values[0]은 이 레코드에 대한 결과 값\n",
    "        targets[int(all_values[0])] =0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "\n",
    "# mnist 테스트 데이터 \n",
    "training_data_file = open(\"mnist_dataset/mnist_test.csv\", 'r')\n",
    "# readlines() 는 쉽지만 불러오는 데이터 너무 클떄는 전체파일을 메모리에 올리기 떄문에 비효율\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# 신경망 테스트 \n",
    "\n",
    "# 신경망의 성능의 지표가 되는 성적표 초기화 \n",
    "scorecard = []\n",
    "\n",
    "# 학습 데이터 모음 내의 모든 레코드 탐색\n",
    "for record in training_data_list:\n",
    "    # 레코드를 쉼표에 의해 분리\n",
    "    all_values = record.split(',')\n",
    "    # 정답은 첫번째 값\n",
    "    correct_label = int(all_values[0])\n",
    "#     print (correct_label, \"correct label\")\n",
    "    # asfarray() 문자열을 실수로 변환 한 다음에 그 숫자로 구성된 배열을 생성\n",
    "    # reshape((28,28)) 는 28*28의 정방행렬로 만들어줌\n",
    "    # image_array = numpy.asfarray(all_values[1:]).reshape((28, 28))\n",
    "    # cmap = 'Greys' 를 지정해 회색톤의 색상 팔레트를 사용\n",
    "    # matplotlib.pyplot.imshow(image_array, cmap ='Greys', interpolation='None')\n",
    "    \n",
    "    # 입력 값의 범위와 값 조정\n",
    "    inputs = (numpy.asfarray(all_values[1:])/255.0 * 0.99) +0.01\n",
    "    \n",
    "    # 신경망에 질의\n",
    "    output = n.query(inputs)\n",
    "    # 가장 높은 값의 인덱스는 레이블의 인덱스와 일치\n",
    "    # argmax 가장 큰값을 찾아 그 위치를 알려주는 함수\n",
    "    label = numpy.argmax(output)\n",
    "#     print(label, \"network's answer\")\n",
    "    \n",
    "    # 정답 또는 오답을 리스트에 추가\n",
    "    if(label == correct_label):\n",
    "        # 정답인 경우 성적표에 1을 더함\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # 정답이 아닌 경우 성적표에 0을 더함\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# 정답의 비율인 성적을 계산해 출력\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print(\"performance = \", scorecard_array.sum() / scorecard_array.size)\n",
    "\n",
    "#     # 결과 값 생성 (실제 값이 0.99 외에는 모두 0.01)\n",
    "#     targets = numpy.zeros(output_nodes)+0.01\n",
    "#     # all_values[0]은 이 레코드에 대한 결과 값\n",
    "#     targets[int(all_values[0])] = 0.99\n",
    "#     n.train(inputs, targets)\n",
    "    \n",
    "#     pass\n",
    "# Xh = Wi * Input\n",
    "# hidden_inputs = numpy.dot(self.wih inputs)\n",
    "# numpy.dot 같은 방법을 통해 바로 계산가능\n",
    "# 은닉 계층에서 나오는 값은\n",
    "# Oh = sigmoid(Xh)\n",
    "# TODO 왜 가중치의 나누기를 하는걸까? 값과 가중치의 곱일수도 있는데.. \n",
    "# 경사 하강법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.3\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "numpy.random.rand(3, 3) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44642062],\n",
       "       [ 0.43735163],\n",
       "       [ 0.39105812]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = open(\"mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "# readlines() 는 쉽지만 불러오는 데이터 너무 클떄는 전체파일을 메모리에 올리기 떄문에 비효율\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x116c24e10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUP8PRZ8Vlgh2BcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f103438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "all_values = data_list[0].split(',')\n",
    "# asfarray() 문자열을 실수로 변환 한 다음에 그 숫자로 구성된 배열을 생성\n",
    "# reshape((28,28)) 는 28*28의 정방행렬로 만들어줌\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28, 28))\n",
    "# cmap = 'Greys' 를 지정해 회색톤의 색상 팔레트를 사용\n",
    "matplotlib.pyplot.imshow(image_array, cmap ='Greys', interpolation='None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.02164706\n",
      "  0.07988235  0.07988235  0.07988235  0.49917647  0.538       0.68941176\n",
      "  0.11094118  0.65447059  1.          0.96894118  0.50305882  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.12647059  0.14976471  0.37494118\n",
      "  0.60788235  0.67        0.99223529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.88352941  0.67776471  0.99223529  0.94952941  0.76705882\n",
      "  0.25847059  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.20023529\n",
      "  0.934       0.99223529  0.99223529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.99223529  0.99223529  0.98447059  0.37105882  0.32835294\n",
      "  0.32835294  0.22741176  0.16141176  0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.07988235  0.86023529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.99223529  0.77870588  0.71658824  0.96894118  0.94564706\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.32058824  0.61564706\n",
      "  0.42541176  0.99223529  0.99223529  0.80588235  0.05270588  0.01\n",
      "  0.17694118  0.60788235  0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.06435294  0.01388235  0.60788235  0.99223529  0.35941176  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.54964706  0.99223529  0.74764706  0.01776471\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.05270588  0.74764706  0.99223529\n",
      "  0.28176471  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.14588235\n",
      "  0.94564706  0.88352941  0.63117647  0.42929412  0.01388235  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.32447059  0.94176471  0.99223529  0.99223529  0.472       0.10705882\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.18470588  0.73211765  0.99223529  0.99223529\n",
      "  0.59235294  0.11482353  0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.07211765  0.37105882\n",
      "  0.98835294  0.99223529  0.736       0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.97670588  0.99223529  0.97670588  0.25847059  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.18858824  0.51470588\n",
      "  0.72047059  0.99223529  0.99223529  0.81364706  0.01776471  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.16141176  0.58458824  0.89905882\n",
      "  0.99223529  0.99223529  0.99223529  0.98058824  0.71658824  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.10317647  0.45258824  0.868       0.99223529\n",
      "  0.99223529  0.99223529  0.99223529  0.79035294  0.31282353  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.09929412  0.26623529  0.83694118  0.99223529  0.99223529\n",
      "  0.99223529  0.99223529  0.77870588  0.32447059  0.01776471  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.07988235  0.67388235  0.86023529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.76705882  0.32058824  0.04494118  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.22352941  0.67776471  0.88741176  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.95729412  0.52635294  0.05270588  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.538       0.99223529  0.99223529  0.99223529  0.83305882\n",
      "  0.53411765  0.52247059  0.07211765  0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01      ]\n"
     ]
    }
   ],
   "source": [
    "# 0~255의 값을 가지는 색상값을 255로 나눈뒤 0.99를 곱하고 0.01 을 더하여 0.01 ~ 1 사이의 값을 갖도록 함\n",
    "# 입력값이 0을 가지면 가중치 없데이트를 없애버리므로 안좋음\n",
    "scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99)+ 0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 출력 계층의 노드 수를 10으로 0~9 까지 나와야하니...\n",
    "onodes = 10\n",
    "targets = numpy.zeros(onodes) + 0.01\n",
    "targets[int(all_values[0])] = 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01  0.01  0.01  0.01  0.01  0.99  0.01  0.01  0.01  0.01]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n"
     ]
    }
   ],
   "source": [
    "print(\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
